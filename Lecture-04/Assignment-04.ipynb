{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assignment-04"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# . 复习上课内容以及复现课程代码"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-09T08:02:01.930172Z",
     "start_time": "2019-11-09T08:02:01.922223Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import random\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "##  课堂代码"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-09T03:12:01.829751Z",
     "start_time": "2019-11-09T03:12:01.793880Z"
    },
    "code_folding": [
     0,
     73,
     99,
     144
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "class Node:\n",
    "    def __init__(self, inputs=[]):\n",
    "        self.inputs = inputs\n",
    "        self.outputs = []\n",
    "\n",
    "        for n in self.inputs:\n",
    "            n.outputs.append(self)\n",
    "            # set 'self' node as inbound_nodes's outbound_nodes\n",
    "\n",
    "        self.value = None\n",
    "\n",
    "        self.gradients = {}\n",
    "        # keys are the inputs to this node, and their\n",
    "        # values are the partials of this node with \n",
    "        # respect to that input.\n",
    "        # \\partial{node}{input_i}\n",
    "        \n",
    "\n",
    "    def forward(self):\n",
    "        '''\n",
    "        Forward propagation. \n",
    "        Compute the output value vased on 'inbound_nodes' and store the \n",
    "        result in self.value\n",
    "        '''\n",
    "\n",
    "        raise NotImplemented\n",
    "    \n",
    "\n",
    "    def backward(self):\n",
    "\n",
    "        raise NotImplemented\n",
    "        \n",
    "class Input(Node):\n",
    "    def __init__(self):\n",
    "        '''\n",
    "        An Input node has no inbound nodes.\n",
    "        So no need to pass anything to the Node instantiator.\n",
    "        '''\n",
    "        Node.__init__(self)\n",
    "\n",
    "    def forward(self, value=None):\n",
    "        '''\n",
    "        Only input node is the node where the value may be passed\n",
    "        as an argument to forward().\n",
    "        All other node implementations should get the value of the \n",
    "        previous node from self.inbound_nodes\n",
    "        \n",
    "        Example: \n",
    "        val0: self.inbound_nodes[0].value\n",
    "        '''\n",
    "        if value is not None:\n",
    "            self.value = value\n",
    "            ## It's is input node, when need to forward, this node initiate self's value.\n",
    "\n",
    "        # Input subclass just holds a value, such as a data feature or a model parameter(weight/bias)\n",
    "        \n",
    "    def backward(self):\n",
    "        self.gradients = {self:0}\n",
    "        for n in self.outputs:\n",
    "            grad_cost = n.gradients[self]\n",
    "            self.gradients[self] = grad_cost * 1\n",
    "            \n",
    "        \n",
    "        # input N --> N1, N2\n",
    "        # \\partial L / \\partial N \n",
    "        # ==> \\partial L / \\partial N1 * \\ partial N1 / \\partial N\n",
    "\n",
    "\n",
    "class Add(Node):\n",
    "    def __init__(self, *nodes):\n",
    "        Node.__init__(self, nodes)\n",
    "\n",
    "\n",
    "    def forward(self):\n",
    "        self.value = sum(map(lambda n: n.value, self.inputs))\n",
    "        ## when execute forward, this node caculate value as defined.\n",
    "\n",
    "class Linear(Node):\n",
    "    def __init__(self, nodes, weights, bias):\n",
    "        Node.__init__(self, [nodes, weights, bias])\n",
    "\n",
    "    def forward(self):\n",
    "        inputs = self.inputs[0].value\n",
    "        weights = self.inputs[1].value\n",
    "        bias = self.inputs[2].value\n",
    "\n",
    "        self.value = np.dot(inputs, weights) + bias\n",
    "        \n",
    "    def backward(self):\n",
    "\n",
    "        # initial a partial for each of the inbound_nodes.\n",
    "        self.gradients = {n: np.zeros_like(n.value) for n in self.inputs}\n",
    "\n",
    "        for n in self.outputs:\n",
    "            # Get the partial of the cost w.r.t this node.\n",
    "            grad_cost = n.gradients[self]\n",
    "\n",
    "            self.gradients[self.inputs[0]] = np.dot(grad_cost, self.inputs[1].value.T)\n",
    "            self.gradients[self.inputs[1]] = np.dot(self.inputs[0].value.T, grad_cost)\n",
    "            self.gradients[self.inputs[2]] = np.sum(grad_cost, axis=0, keepdims=False)\n",
    "\n",
    "        # WX + B / W ==> X\n",
    "        # WX + B / X ==> W\n",
    "\n",
    "class Sigmoid(Node):\n",
    "    def __init__(self, node):\n",
    "        Node.__init__(self, [node])\n",
    "\n",
    "\n",
    "    def _sigmoid(self, x):\n",
    "        return 1./(1 + np.exp(-1 * x))\n",
    "\n",
    "    def forward(self):\n",
    "        self.x = self.inputs[0].value\n",
    "        self.value = self._sigmoid(self.x)\n",
    "\n",
    "    def backward(self):\n",
    "        self.partial = self._sigmoid(self.x) * (1 - self._sigmoid(self.x))\n",
    "        \n",
    "        # y = 1 / (1 + e^-x)\n",
    "        # y' = 1 / (1 + e^-x) (1 - 1 / (1 + e^-x))\n",
    "        \n",
    "        self.gradients = {n: np.zeros_like(n.value) for n in self.inputs}\n",
    "\n",
    "        for n in self.outputs:\n",
    "            grad_cost = n.gradients[self]  # Get the partial of the cost with respect to this node.\n",
    "\n",
    "            self.gradients[self.inputs[0]] = grad_cost * self.partial\n",
    "            # use * to keep all the dimension same!.\n",
    "\n",
    "\n",
    "\n",
    "class MSE(Node):\n",
    "    def __init__(self, y, a):\n",
    "        Node.__init__(self, [y, a])\n",
    "\n",
    "\n",
    "    def forward(self):\n",
    "        y = self.inputs[0].value.reshape(-1, 1)\n",
    "        a = self.inputs[1].value.reshape(-1, 1)\n",
    "        assert(y.shape == a.shape)\n",
    "\n",
    "        self.m = self.inputs[0].value.shape[0]\n",
    "        self.diff = y - a\n",
    "\n",
    "        self.value = np.mean(self.diff**2)\n",
    "\n",
    "\n",
    "    def backward(self):\n",
    "        self.gradients[self.inputs[0]] = (2 / self.m) * self.diff\n",
    "        self.gradients[self.inputs[1]] = (-2 / self.m) * self.diff\n",
    "\n",
    "\n",
    "def forward_and_backward(outputnode, graph):\n",
    "    # execute all the forward method of sorted_nodes.\n",
    "\n",
    "    ## In practice, it's common to feed in mutiple data example in each forward pass rather than just 1. Because the examples can be processed in parallel. The number of examples is called batch size.\n",
    "    for n in graph:\n",
    "        n.forward()\n",
    "        ## each node execute forward, get self.value based on the topological sort result.\n",
    "\n",
    "    for n in  graph[::-1]:\n",
    "        n.backward()\n",
    "\n",
    "    #return outputnode.value\n",
    "\n",
    "###   v -->  a -->  C\n",
    "##    b --> C\n",
    "##    b --> v -- a --> C\n",
    "##    v --> v ---> a -- > C\n",
    "\n",
    "def topological_sort(feed_dict):\n",
    "    \"\"\"\n",
    "    Sort generic nodes in topological order using Kahn's Algorithm.\n",
    "    `feed_dict`: A dictionary where the key is a `Input` node and the value is the respective value feed to that node.\n",
    "    Returns a list of sorted nodes.\n",
    "    \"\"\"\n",
    "\n",
    "    input_nodes = [n for n in feed_dict.keys()]\n",
    "\n",
    "    G = {}\n",
    "    nodes = [n for n in input_nodes]\n",
    "    while len(nodes) > 0:\n",
    "        n = nodes.pop(0)\n",
    "        if n not in G:\n",
    "            G[n] = {'in': set(), 'out': set()}\n",
    "        for m in n.outputs:\n",
    "            if m not in G:\n",
    "                G[m] = {'in': set(), 'out': set()}\n",
    "            G[n]['out'].add(m)\n",
    "            G[m]['in'].add(n)\n",
    "            nodes.append(m)\n",
    "\n",
    "    L = []\n",
    "    S = set(input_nodes)\n",
    "    while len(S) > 0:\n",
    "        n = S.pop()\n",
    "\n",
    "        if isinstance(n, Input):\n",
    "            n.value = feed_dict[n]\n",
    "            ## if n is Input Node, set n'value as \n",
    "            ## feed_dict[n]\n",
    "            ## else, n's value is caculate as its\n",
    "            ## inbounds\n",
    "\n",
    "        L.append(n)\n",
    "        for m in n.outputs:\n",
    "            G[n]['out'].remove(m)\n",
    "            G[m]['in'].remove(n)\n",
    "            # if no other incoming edges add to S\n",
    "            if len(G[m]['in']) == 0:\n",
    "                S.add(m)\n",
    "    return L\n",
    "\n",
    "\n",
    "def sgd_update(trainables, learning_rate=1e-2):\n",
    "    # there are so many other update / optimization methods\n",
    "    # such as Adam, Mom, \n",
    "    for t in trainables:\n",
    "        t.value += -1 * learning_rate * t.gradients[t]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-09T03:12:04.507994Z",
     "start_time": "2019-11-09T03:12:04.504005Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_boston"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-09T03:12:07.674115Z",
     "start_time": "2019-11-09T03:12:05.573143Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'sklearn.utils.Bunch'> dict_keys(['data', 'target', 'feature_names', 'DESCR', 'filename'])\n"
     ]
    }
   ],
   "source": [
    "data= load_boston()\n",
    "print(type(data), data.keys())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "\"\"\"\n",
    "Check out the new network architecture and dataset!\n",
    "\n",
    "Notice that the weights and biases are generated randomly.\n",
    "\n",
    "No need to change anything, but feel free to tweak\n",
    "\n",
    "to test your network, play around with the epochs, batch size, etc!\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-09T03:12:10.720758Z",
     "start_time": "2019-11-09T03:12:10.716796Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "epochs = 5000\n",
    "n_hidden = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-09T03:12:39.537626Z",
     "start_time": "2019-11-09T03:12:13.817221Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of examples = 506\n",
      "Epoch: 1, Loss: 182.282\n",
      "Epoch: 101, Loss: 6.926\n",
      "Epoch: 201, Loss: 5.854\n",
      "Epoch: 301, Loss: 4.847\n",
      "Epoch: 401, Loss: 5.574\n",
      "Epoch: 501, Loss: 5.057\n",
      "Epoch: 601, Loss: 3.625\n",
      "Epoch: 701, Loss: 4.487\n",
      "Epoch: 801, Loss: 3.871\n",
      "Epoch: 901, Loss: 3.609\n",
      "Epoch: 1001, Loss: 4.240\n",
      "Epoch: 1101, Loss: 4.050\n",
      "Epoch: 1201, Loss: 3.996\n",
      "Epoch: 1301, Loss: 3.685\n",
      "Epoch: 1401, Loss: 4.776\n",
      "Epoch: 1501, Loss: 4.095\n",
      "Epoch: 1601, Loss: 4.077\n",
      "Epoch: 1701, Loss: 3.754\n",
      "Epoch: 1801, Loss: 4.016\n",
      "Epoch: 1901, Loss: 4.272\n",
      "Epoch: 2001, Loss: 3.484\n",
      "Epoch: 2101, Loss: 4.105\n",
      "Epoch: 2201, Loss: 4.143\n",
      "Epoch: 2301, Loss: 4.041\n",
      "Epoch: 2401, Loss: 3.459\n",
      "Epoch: 2501, Loss: 3.238\n",
      "Epoch: 2601, Loss: 3.601\n",
      "Epoch: 2701, Loss: 4.017\n",
      "Epoch: 2801, Loss: 3.733\n",
      "Epoch: 2901, Loss: 3.907\n",
      "Epoch: 3001, Loss: 3.851\n",
      "Epoch: 3101, Loss: 4.317\n",
      "Epoch: 3201, Loss: 3.068\n",
      "Epoch: 3301, Loss: 3.740\n",
      "Epoch: 3401, Loss: 3.795\n",
      "Epoch: 3501, Loss: 3.487\n",
      "Epoch: 3601, Loss: 3.978\n",
      "Epoch: 3701, Loss: 4.165\n",
      "Epoch: 3801, Loss: 4.103\n",
      "Epoch: 3901, Loss: 3.724\n",
      "Epoch: 4001, Loss: 2.943\n",
      "Epoch: 4101, Loss: 4.121\n",
      "Epoch: 4201, Loss: 3.325\n",
      "Epoch: 4301, Loss: 4.197\n",
      "Epoch: 4401, Loss: 3.629\n",
      "Epoch: 4501, Loss: 3.572\n",
      "Epoch: 4601, Loss: 3.707\n",
      "Epoch: 4701, Loss: 3.927\n",
      "Epoch: 4801, Loss: 3.771\n",
      "Epoch: 4901, Loss: 3.513\n"
     ]
    }
   ],
   "source": [
    "losses = []\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.utils import shuffle, resample\n",
    "\n",
    "data = load_boston()\n",
    "X_ = data['data']\n",
    "y_ = data['target']\n",
    "\n",
    "\n",
    "# Normalize data\n",
    "X_ = (X_ - np.mean(X_, axis=0)) / np.std(X_, axis=0)\n",
    "\n",
    "n_features = X_.shape[1]\n",
    "W1_ = np.random.randn(n_features, n_hidden)\n",
    "b1_ = np.zeros(n_hidden)\n",
    "W2_ = np.random.randn(n_hidden, 1)\n",
    "b2_ = np.zeros(1)\n",
    "\n",
    "# Neural network\n",
    "X, y = Input(), Input()\n",
    "W1, b1 = Input(), Input()\n",
    "W2, b2 = Input(), Input()\n",
    "\n",
    "l1 = Linear(X, W1, b1)\n",
    "s1 = Sigmoid(l1)\n",
    "l2 = Linear(s1, W2, b2)\n",
    "cost = MSE(y, l2)\n",
    "\n",
    "feed_dict = {\n",
    "    X: X_,\n",
    "    y: y_,\n",
    "    W1: W1_,\n",
    "    b1: b1_,\n",
    "    W2: W2_,\n",
    "    b2: b2_\n",
    "}\n",
    "\n",
    "m = X_.shape[0]\n",
    "batch_size = 16\n",
    "steps_per_epoch = m // batch_size\n",
    "\n",
    "graph = topological_sort(feed_dict)\n",
    "trainables = [W1, b1, W2, b2]\n",
    "\n",
    "print(\"Total number of examples = {}\".format(m))\n",
    "\n",
    "# Step 4\n",
    "for i in range(epochs):\n",
    "    loss = 0\n",
    "    for j in range(steps_per_epoch):\n",
    "        # Step 1\n",
    "        # Randomly sample a batch of examples\n",
    "        X_batch, y_batch = resample(X_, y_, n_samples=batch_size)\n",
    "\n",
    "        # Reset value of X and y Inputs\n",
    "        X.value = X_batch\n",
    "        y.value = y_batch\n",
    "\n",
    "        # Step 2\n",
    "        _ = None\n",
    "        forward_and_backward(_, graph) # set output node not important.\n",
    "\n",
    "        # Step 3\n",
    "        rate = 1e-2\n",
    "    \n",
    "        sgd_update(trainables, rate)\n",
    "\n",
    "        loss += graph[-1].value\n",
    "    \n",
    "    if i % 100 == 0: \n",
    "        print(\"Epoch: {}, Loss: {:.3f}\".format(i+1, loss/steps_per_epoch))\n",
    "        losses.append(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-09T03:13:39.134803Z",
     "start_time": "2019-11-09T03:13:38.289066Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x2cd246ca828>]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(range(len(losses)), losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-09T03:13:42.341190Z",
     "start_time": "2019-11-09T03:13:42.334246Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 5.82318386],\n",
       "       [ 3.86922848],\n",
       "       [ 9.34185796],\n",
       "       [-4.04553477],\n",
       "       [ 2.9117156 ],\n",
       "       [ 4.9552698 ],\n",
       "       [ 5.87589513],\n",
       "       [12.57094081],\n",
       "       [10.25077736],\n",
       "       [ 9.31309672]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W2.value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-08T23:13:36.154225Z",
     "start_time": "2019-11-08T23:13:36.150243Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-09T04:05:38.278700Z",
     "start_time": "2019-11-09T04:05:38.271719Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.41978194,  0.28482986, -1.2879095 , -0.27259857, -0.14421743,\n",
       "        0.41367189, -0.12001342,  0.1402136 , -0.98284286, -0.66660821,\n",
       "       -1.45900038,  0.44105193, -1.0755623 ])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "##  tensorflow 实现"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-10T06:01:28.249063Z",
     "start_time": "2019-11-10T06:01:28.240087Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#迭代次数\n",
    "train_epochs = 500\n",
    "#学习率\n",
    "learning_rate = 0.01\n",
    "# 打印结果\n",
    "print_grap = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-10T06:06:17.854772Z",
     "start_time": "2019-11-10T06:04:59.077395Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# 准备好placeholder\n",
    "x = tf.placeholder(tf.float32,[None,13],name=\"X\")\n",
    "y = tf.placeholder(tf.float32,[None, 1],name=\"Y\")\n",
    "\n",
    "# 初始化参数/权重\n",
    "W = tf.Variable(tf.random_normal([13,1],stddev=0.01), name='weight')\n",
    "b = tf.Variable(1.0, name='bias')# 初始化参数/权重\n",
    "\n",
    "# b = tf.Variable(tf.random_normal([]), name='bias')# 初始化参数/权重\n",
    "\n",
    "#创建一个简单的神经网络\n",
    "prediction = tf.matmul(x,W)+b\n",
    "\n",
    "#二次代价函数 :MSE\n",
    "loss = tf.reduce_mean(tf.square(y-prediction))\n",
    "#使用梯度下降法\n",
    "train_step = tf.train.GradientDescentOptimizer(learning_rate).minimize(loss)\n",
    "\n",
    "#初始化变量\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "losses_tf = []\n",
    "\n",
    "#train\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    for epoch in range(train_epochs):\n",
    "        \n",
    "        loss_sum = 0.0\n",
    "        \n",
    "        for xs, ys in zip(X_, y_):\n",
    "            xs = xs.reshape(1,13)\n",
    "            ys = ys.reshape(1,1)\n",
    "            _, loss_epocch = sess.run([train_step, loss],feed_dict={x:xs,y:ys})\n",
    "            loss_sum += loss_epocch\n",
    "            \n",
    "        # 完成一次更新就 打乱数据顺序\n",
    "        X_, y_ = shuffle(X_, y_)\n",
    "        b_temp = b.eval(session = sess)\n",
    "        W_temp = W.eval(session=sess)\n",
    "        \n",
    "        loss_average = loss_sum / X_.shape[0]\n",
    "        \n",
    "#         losses_tf.append(loss_average)\n",
    "        \n",
    "        if epoch % print_grap == 0:\n",
    "            losses_tf.append(loss_average)\n",
    "#             print(\"epoch=\",epoch+1,\"loss(MSE)=\",loss_average,\"b=\",b_temp,\"w=\",W_temp)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-10T06:06:22.714858Z",
     "start_time": "2019-11-10T06:06:22.554286Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x2cd2d8e19b0>]"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(range(len(losses_tf)), losses_tf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-09T06:38:41.289442Z",
     "start_time": "2019-11-09T06:38:35.525930Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: keras in d:\\programdata\\anaconda3\\lib\\site-packages (2.3.1)\n",
      "Requirement already satisfied: numpy>=1.9.1 in d:\\programdata\\anaconda3\\lib\\site-packages (from keras) (1.15.4)\n",
      "Requirement already satisfied: scipy>=0.14 in d:\\programdata\\anaconda3\\lib\\site-packages (from keras) (1.1.0)\n",
      "Requirement already satisfied: six>=1.9.0 in d:\\programdata\\anaconda3\\lib\\site-packages (from keras) (1.12.0)\n",
      "Requirement already satisfied: keras-applications>=1.0.6 in d:\\programdata\\anaconda3\\lib\\site-packages (from keras) (1.0.8)\n",
      "Requirement already satisfied: pyyaml in d:\\programdata\\anaconda3\\lib\\site-packages (from keras) (3.13)\n",
      "Requirement already satisfied: h5py in d:\\programdata\\anaconda3\\lib\\site-packages (from keras) (2.8.0)\n",
      "Requirement already satisfied: keras-preprocessing>=1.0.5 in d:\\programdata\\anaconda3\\lib\\site-packages (from keras) (1.1.0)\n"
     ]
    }
   ],
   "source": [
    "! pip install keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-08T23:16:12.195400Z",
     "start_time": "2019-11-08T23:16:12.015882Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'tensorflow.python.keras.backend' has no attribute 'get_graph'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-25-fff9860591be>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mDense\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mSequential\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0m__future__\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mabsolute_import\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mutils\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mactivations\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mapplications\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\utils\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdata_utils\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mio_utils\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mconv_utils\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mlosses_utils\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmetrics_utils\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\utils\\conv_utils.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmoves\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mbackend\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mK\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\backend\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mload_backend\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mepsilon\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mload_backend\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mset_epsilon\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mload_backend\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mfloatx\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mload_backend\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mset_floatx\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mload_backend\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcast_to_floatx\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\backend\\load_backend.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     88\u001b[0m \u001b[1;32melif\u001b[0m \u001b[0m_BACKEND\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'tensorflow'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     89\u001b[0m     \u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstderr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Using TensorFlow backend.\\n'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 90\u001b[1;33m     \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mtensorflow_backend\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     91\u001b[0m \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     92\u001b[0m     \u001b[1;31m# Try and load external backend.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m \u001b[1;31m# Private TF Keras utils\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 54\u001b[1;33m \u001b[0mget_graph\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_keras_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_graph\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     55\u001b[0m \u001b[1;31m# learning_phase_scope = tf_keras_backend.learning_phase_scope  # TODO\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     56\u001b[0m \u001b[0mname_scope\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'tensorflow.python.keras.backend' has no attribute 'get_graph'"
     ]
    }
   ],
   "source": [
    "from keras.layers import Dense\n",
    "from keras.models import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-08T16:02:59.886037Z",
     "start_time": "2019-11-08T16:02:59.872075Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Sequential' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-19-3457b5965fcc>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSequential\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mDense\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0munits\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m64\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'sigmoid'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_dim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m13\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mDense\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0munits\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m30\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'sigmoid'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_dim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m64\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mDense\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0munits\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'Sequential' is not defined"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(units=64, activation='sigmoid', input_dim=13))\n",
    "model.add(Dense(units=30, activation='sigmoid', input_dim=64))\n",
    "model.add(Dense(units=1))\n",
    "\n",
    "model.compile(loss='mse',\n",
    "              optimizer='sgd',\n",
    "              metrics=['mse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "model.fit(X_, y_, epochs=5000, batch_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# . 回答一下理论题目"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## What does a neuron compute?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "ans:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Why we use non-linear activation funcitons in neural networks?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "ans: 如果是线性的激活函数，那么后面所有的层的导数都是一样的，这样的话就再多的层次也和一层是一样的效果"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## What is the 'Logistic Loss' ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-03T03:32:14.291332Z",
     "start_time": "2019-11-03T03:32:14.282338Z"
    },
    "hidden": true
   },
   "source": [
    "$$loss=-\\frac{1}{(n)}\\sum [y*log \\hat{y}+(1-y)log(1-\\hat{y})]$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Assume that you are building a binary classifier for detecting if an image containing cats, which activation functions would you recommen using for the output layer ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "A. ReLU\n",
    "\n",
    "B. Leaky ReLU\n",
    "\n",
    "C. sigmoid\n",
    "\n",
    "D. tanh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "ans: C sigmoid "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Why we don't use zero initialization for all parameters ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "ans:如果初始化成0，使得更新之后的不同节点的参数相同，不管进行多少轮的正向传播和反向传播，所有节点得到的参数都一样！因此，神经网络就失去了其特征学习的能力"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Can you implement the softmax function using python ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-08T14:58:41.832883Z",
     "start_time": "2019-11-08T14:58:41.827867Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def softmaax(array):\n",
    "    array -= max(array)\n",
    "    return np.exp(array) / sum(np.exp(array))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# .实践题"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据探索"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-09T07:01:41.582799Z",
     "start_time": "2019-11-09T07:01:41.578815Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this practical part, you will build a simple digits recognizer to check if the digit in the image is larger than 5. This assignmnet will guide you step by step to finish your first small project in this course ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2 -  Overvie of the dataset\n",
    "\n",
    ">- a training set has m_train images labeled as 0 if the digit < 5 or 1 if the digit >= 5\n",
    "- a test set contains m_test images labels as if the digit < 5 or 1 if the digit >= 5\n",
    "- eah image if of shape (num_px, num_px ). Thus, each image is square(height=num_px and  width = num_px)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-09T07:06:15.315051Z",
     "start_time": "2019-11-09T07:06:15.228250Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'sklearn.utils.Bunch'> dict_keys(['data', 'target', 'target_names', 'images', 'DESCR'])\n"
     ]
    }
   ],
   "source": [
    "digits = datasets.load_digits()\n",
    "print(type(digits), digits.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-09T07:06:58.746873Z",
     "start_time": "2019-11-09T07:06:58.049600Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 10 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Vilizating the data\n",
    "for i in range(1,11):\n",
    "    plt.subplot(2,5,i)\n",
    "    plt.imshow(digits.data[i-1].reshape([8,8]),cmap=plt.cm.gray_r)\n",
    "    plt.text(3,10,str(digits.target[i-1]))\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "plt.show()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-09T07:07:20.713261Z",
     "start_time": "2019-11-09T07:07:20.705317Z"
    }
   },
   "outputs": [],
   "source": [
    "# Split the data into training set and test set \n",
    "X_train, X_test, y_train, y_test = train_test_split(digits.data, digits.target, test_size=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-09T07:07:57.809452Z",
     "start_time": "2019-11-09T07:07:57.801444Z"
    }
   },
   "outputs": [],
   "source": [
    "# reformulate the label. \n",
    "# If the digit is smaller than 5, the label is 0.\n",
    "# If the digit is larger than 5, the label is 1.\n",
    "\n",
    "y_train[y_train < 5 ] = 0\n",
    "y_train[y_train >= 5] = 1\n",
    "y_test[y_test < 5] = 0\n",
    "y_test[y_test >= 5] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-09T07:08:14.368375Z",
     "start_time": "2019-11-09T07:08:14.361391Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1347, 64)\n",
      "(450, 64)\n",
      "(1347,)\n",
      "(450,)\n"
     ]
    }
   ],
   "source": [
    "print(c.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "##  Architecture of the neural network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Mathematical expression of the algorithm:\n",
    "for one example $x^{(i)}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-09T07:16:26.811488Z",
     "start_time": "2019-11-09T07:16:26.806538Z"
    },
    "hidden": true
   },
   "source": [
    "$$z^{(i)} = w^{T} * x^{(i)} + b$$\n",
    "\n",
    "$$y^{(i)} = a^{(i)}=sigmoid(z^{(i)})$$\n",
    "\n",
    "$$L(a^{(i)},y^{(i)}) = -y^{(i)}log(a^{(i)}) - (1-y^{(i)})log(1-a^{(i)})$$\n",
    "\n",
    "the total cost over all training examples:\n",
    "\n",
    "$$J = \\frac{1}{m}\\sum_{i=1}^{m}L(a^{(i)},y^{(i)})$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Activation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-09T07:56:25.601631Z",
     "start_time": "2019-11-09T07:56:23.579065Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8807970779778823\n",
      "[0.73105858 0.98201379 0.99966465]\n"
     ]
    }
   ],
   "source": [
    "def sigmoid(z):\n",
    "    '''\n",
    "    Compute the sigmoid of z\n",
    "    Arguments: z -- a scalar or numpy array of any size.\n",
    "    \n",
    "    Return:\n",
    "    s -- sigmoid(z)\n",
    "    '''\n",
    "    \n",
    "    return 1.0/(1 + np.exp(-1 * z))\n",
    "print(sigmoid(2))\n",
    "print(sigmoid(np.array([1,4,8])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-09T07:58:11.681253Z",
     "start_time": "2019-11-09T07:58:11.676289Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sigmoid([0,2]) = [0.5        0.88079708]\n"
     ]
    }
   ],
   "source": [
    "# Test your code \n",
    "# The result should be [0.5 0.88079708]\n",
    "print(\"sigmoid([0,2]) = \" + str(sigmoid(np.array([0,2]))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initializaing parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-09T08:10:18.098032Z",
     "start_time": "2019-11-09T08:10:18.092052Z"
    }
   },
   "outputs": [],
   "source": [
    "# Random innitialize the parameters\n",
    "def initialize_parameters(dim):\n",
    "    '''\n",
    "    Argument: dim -- size of the w vector\n",
    "    \n",
    "    Returns:\n",
    "    w -- initialized vector of shape (dim,1)\n",
    "    b -- initializaed scalar\n",
    "    '''\n",
    "    \n",
    "    w = np.random.uniform(0.0,0.5,[dim,1])\n",
    "    b = np.random.uniform(0.0,0.5,1)[0]\n",
    "    print(w.shape,type(b),b)\n",
    "    \n",
    "    assert(w.shape == (dim,1))\n",
    "    assert(isinstance(b,float) or isinstance(b,int))\n",
    "    \n",
    "    return w,b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-09T08:10:18.130945Z",
     "start_time": "2019-11-09T08:10:18.125958Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 1) <class 'numpy.float64'> 0.24060630077173423\n",
      "weitght: [[0.05561277]\n",
      " [0.24725275]\n",
      " [0.28474621]] \n",
      " bias: 0.24060630077173423\n"
     ]
    }
   ],
   "source": [
    "# Test your code \n",
    "# The result should be [0.5 0.88079708]\n",
    "weight, b = initialize_parameters(3)\n",
    "print(f\"weitght: {weight}\",\"\\n\", f\"bias: {b}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Forward and backward propagation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "mathematical expressions\n",
    "\n",
    "Forward Propagation:\n",
    "\n",
    "$X$\n",
    "\n",
    "$A = \\sigma(w^{T} * X + b)=(a^{(1)},a^{(2)},a^{(3)} ...,a^{(m)})$\n",
    "\n",
    "$J = \\frac{-1}{m}\\sum_{i=1}^{m}[y^{i}log(a^{(i)})+(1 - y^{(i)})log(1 - a^{(i)})]$\n",
    "\n",
    "some derivative:\n",
    "\n",
    "$$\\frac{\\partial J}{\\partial w} = \\frac{1}{m}X * (A - Y)^{T}$$\n",
    "\n",
    "$$\\frac{\\partial J}{\\partial b} =\\frac{1}{m}\\sum_{i=1}^{m}(a^{(i)} - y^{(i)})$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-09T15:29:34.177619Z",
     "start_time": "2019-11-09T15:29:34.171638Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 2],\n",
       "       [3, 4]])"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array([[1,2],[3,4]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-09T15:48:12.313143Z",
     "start_time": "2019-11-09T15:48:12.306193Z"
    }
   },
   "outputs": [],
   "source": [
    "def propagate(w, b, X, Y):\n",
    "    \"\"\"\n",
    "    Implement the cost function and its gradient for the propagation\n",
    "    \n",
    "    Arguments:\n",
    "    w - weights\n",
    "    b - bias\n",
    "    X - data\n",
    "    Y - ground truth\n",
    "    \"\"\"\n",
    "    \n",
    "    m = X.shape[1]\n",
    "    A = [sigmoid(np.dot(w.T, X_i) + b) for X_i in X]\n",
    "    cost = -1 * sum([y_i * np.log(a_i)+(1 - y_i)*np.log(1 - a_i) for a_i,y_i in zip(A,y)]) / m \n",
    "\n",
    "    \n",
    "    dw = X * (A - Y).T / m\n",
    "    db = sum([a_i - y_i for a_i,y_i in zip(A, Y)])\n",
    "    \n",
    "    assert(dw.shape == w.shape)\n",
    "    assert(db.dtype == float)\n",
    "    cost = np.squeeze(cost)\n",
    "    assert(cost.shape == ())\n",
    "    \n",
    "    grads = {'dw':dw,\n",
    "             'db':db}\n",
    "    return grads, cost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "minimizing the cost function using gradient descent\n",
    "\n",
    "$$\\theta = \\theta - \\alpha * d\\theta$$\n",
    "\n",
    "where $\\alpha$ is the learning rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### optimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-10T08:31:36.618778Z",
     "start_time": "2019-11-10T08:31:36.602814Z"
    }
   },
   "outputs": [],
   "source": [
    "def optimize(w, b, X, Y, num_iterations, learning_rate, print_cost=False):\n",
    "    '''\n",
    "    This function optimize w and b by running a gradient descen algorithm\n",
    "    \n",
    "    Arguments:\n",
    "    w - weights\n",
    "    b - bias\n",
    "    X - data\n",
    "    Y - ground truth\n",
    "    num_iterations -- number of iterations of the optimization loop\n",
    "    learning_rate -- learning rate of the gradient descent update rule\n",
    "    print_cost -- True to print the loss every 100 steps\n",
    "    \n",
    "    Returns:\n",
    "    params - dictionary containing the weights w and bias b\n",
    "    grads -- dictionary containing the gradients of the weights and bias with respect to the cost function\n",
    "    costs -- list of all the costs computed during the optimization, this will be used to plot the learning curve.\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    costs = []\n",
    "    \n",
    "    for i in range(num_iterations):\n",
    "        \n",
    "        grads, cost = propagate(w, b, X, Y)\n",
    "        \n",
    "        dw = grads['dw']\n",
    "        db = grads['db']\n",
    "        \n",
    "        w -= learning_rate * dw\n",
    "        b -= learning_rate * db\n",
    "        \n",
    "        if i % 100 == 0:\n",
    "            costs.append(cost)\n",
    "        if print_cost and i % 100 == 0:\n",
    "            print (\"Cost after iteration %i: %f\" %(i, cost))\n",
    "    \n",
    "    params = {\"w\":w,\n",
    "              \"b\":b}\n",
    "    \n",
    "    grads = {\"dw\":dw,\n",
    "             \"db\":db}\n",
    "    \n",
    "    return params, grads, costs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### predict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The previous function will output the learned w and b. We are able to use w and b to predict the labels for a dataset X. Implement the predict() function.\n",
    "Two steps to finish this task:\n",
    "\n",
    ">1. Calculate $\\hat{Y} = A = \\sigma(w^T*X+b)$\n",
    "\n",
    ">2. Convert the entries of a into 0 (if activation <= 0.5) or 1 (if activation > 0.5), stores the predictions in a vector Y_prediction. If you wish, you can use an if/else statement in a for loop (though there is also a way to vectorize this)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-10T08:31:41.510479Z",
     "start_time": "2019-11-10T08:31:41.498999Z"
    }
   },
   "outputs": [],
   "source": [
    "def predict(w, b, X):\n",
    "    '''\n",
    "    Predict whether the label is 0 or 1 using learned logistic regression parameters (w, b)\n",
    "    \n",
    "    Arguments:\n",
    "    w -- weights\n",
    "    b -- bias \n",
    "    X -- data \n",
    "    \n",
    "    Returns:\n",
    "    Y_prediction -- a numpy array (vector) containing all predictions (0/1) for the examples in X\n",
    "    '''\n",
    "    m = X.shape[1]\n",
    "    Y_prediction = np.zeros((1,m))\n",
    "    w = w.reshape(X.shape[0],1)\n",
    "    \n",
    "    A = [sigmoid(np.dot(w.T, X_i) + b) for X_i in X]\n",
    "    \n",
    "    for i in range(A.shape[1]):\n",
    "        Y_prediction[i] = 0 if A[i] < 5 else 1  \n",
    "    \n",
    "    assert(Y_prediction.shape == (1,m))\n",
    "    \n",
    "    return Y_prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge all functions into a model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Congratulations !! You have finished all the necessary components for constructing a model. Now, Let's take the challenge to merge all the implemented function into one model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-10T08:31:45.401365Z",
     "start_time": "2019-11-10T08:31:45.390321Z"
    }
   },
   "outputs": [],
   "source": [
    "def accuracy(y_true,y_hat):\n",
    "    \"\"\"计算准确率\n",
    "    \"\"\"\n",
    "    temp = [ 1 if y_hat_i == y_i else 0 for y_hat_i,y_i in zip(y_hat,y_true)]\n",
    "    \n",
    "    return sum(np.array(temp))/len(y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-10T08:31:48.019064Z",
     "start_time": "2019-11-10T08:31:48.004904Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "def model(X_train, Y_train, X_test, Y_test, num_iterations, learning_rate,print_cost):\n",
    "    \"\"\"\n",
    "    Build the logistic regression model by calling all the functions you have implemented.\n",
    "    Arguments:\n",
    "    X_train - training set\n",
    "    Y_train - training label\n",
    "    X_test - test set\n",
    "    Y_test - test label\n",
    "    num_iteration - hyperparameter representing the number of iterations to optimize the parameters\n",
    "    learning_rate -- hyperparameter representing the learning rate used in the update rule of optimize()\n",
    "    print_cost -- Set to true to print the cost every 100 iterations\n",
    "    \n",
    "    Returns:\n",
    "    d - dictionary should contain following information w,b,training_accuracy, test_accuracy,cost\n",
    "    eg: d = {\"w\":w,\n",
    "             \"b\":b,\n",
    "             \"training_accuracy\": traing_accuracy,\n",
    "             \"test_accuracy\":test_accuracy,\n",
    "             \"cost\":cost}\n",
    "    \"\"\"\n",
    "    d = {\"w\":None, \"b\":None, \"training_accuracy\":None, \"test_accuracy\":None, \"cost\":None}\n",
    "    \n",
    "    # 初始化 W,B\n",
    "    w,b = initialize_parameters(X_train.shape[1])\n",
    "    \n",
    "    # 迭代\n",
    "    params, grads, costs = optimize(w, b, X_train, Y_train, num_iterations, learning_rate, print_cost=False)\n",
    "    \n",
    "    # 计算train/test 上的 accuracy\n",
    "    training_acc = accuracy(Y_train, predict(params[\"w\"], params[\"b\"], X_train))\n",
    "    test_acc = accuracy(Y_test, predict(params[\"w\"], params[\"b\"], X_test))\n",
    "    \n",
    "    d[\"w\"] = params[\"w\"]\n",
    "    d[\"b\"] = params[\"b\"]\n",
    "    d[\"training_accuracy\"] = training_acc\n",
    "    d[\"test_accuracy\"] = test_acc\n",
    "    d[\"cost\"]  = costs\n",
    "    \n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-10T08:31:50.612243Z",
     "start_time": "2019-11-10T08:31:50.028726Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 1) <class 'numpy.float64'> 0.2707894229813339\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Tensor objects are not iterable when eager execution is not enabled. To iterate over this tensor use tf.map_fn.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-144-542b8e1beedf>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mnum_iterations\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m10\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mlearning_rate\u001b[0m \u001b[1;33m=\u001b[0m  \u001b[1;36m0.01\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mresult_dict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_iterations\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mprint_cost\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-143-827ba329b9e9>\u001b[0m in \u001b[0;36mmodel\u001b[1;34m(X_train, Y_train, X_test, Y_test, num_iterations, learning_rate, print_cost)\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m     \u001b[1;31m# 迭代\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 28\u001b[1;33m     \u001b[0mparams\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrads\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcosts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moptimize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mw\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_iterations\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprint_cost\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     29\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m     \u001b[1;31m# 计算train/test 上的 accuracy\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-140-f3804c5b8b5f>\u001b[0m in \u001b[0;36moptimize\u001b[1;34m(w, b, X, Y, num_iterations, learning_rate, print_cost)\u001b[0m\n\u001b[0;32m     23\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnum_iterations\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 25\u001b[1;33m         \u001b[0mgrads\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcost\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpropagate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mw\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     26\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m         \u001b[0mdw\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgrads\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'dw'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-116-3c4d0c6585f6>\u001b[0m in \u001b[0;36mpropagate\u001b[1;34m(w, b, X, Y)\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[0mm\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[0mA\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0msigmoid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mw\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_i\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mX_i\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m     \u001b[0mcost\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0my_i\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma_i\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0my_i\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0ma_i\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0ma_i\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_i\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mA\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mm\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-116-3c4d0c6585f6>\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[0mm\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[0mA\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0msigmoid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mw\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_i\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mX_i\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m     \u001b[0mcost\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0my_i\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma_i\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0my_i\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0ma_i\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0ma_i\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_i\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mA\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mm\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36m__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    434\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    435\u001b[0m       raise TypeError(\n\u001b[1;32m--> 436\u001b[1;33m           \u001b[1;34m\"Tensor objects are not iterable when eager execution is not \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    437\u001b[0m           \"enabled. To iterate over this tensor use tf.map_fn.\")\n\u001b[0;32m    438\u001b[0m     \u001b[0mshape\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_shape_tuple\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: Tensor objects are not iterable when eager execution is not enabled. To iterate over this tensor use tf.map_fn."
     ]
    }
   ],
   "source": [
    "num_iterations = 10\n",
    "learning_rate =  0.01\n",
    "result_dict = model(X_train, y_train, X_test, y_test, num_iterations, learning_rate,print_cost=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 选做题"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Observe the effect of learning rate on the leraning process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-09T15:15:18.776427Z",
     "start_time": "2019-11-09T15:15:18.771408Z"
    }
   },
   "outputs": [],
   "source": [
    "#迭代次数\n",
    "train_epochs = 100\n",
    "#学习率\n",
    "learning_rate_list = [0.005, 0.01,0.02, 0.05, 0.08, 0.1,0.2,0.5]\n",
    "# 打印结果\n",
    "print_grap = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-10T06:40:07.843893Z",
     "start_time": "2019-11-10T06:40:07.839937Z"
    }
   },
   "outputs": [],
   "source": [
    "n_features = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-10T08:23:56.046162Z",
     "start_time": "2019-11-10T07:37:34.477482Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "learning_rate 0.005,Testing Accuracy 1.0\n",
      "learning_rate 0.01,Testing Accuracy 1.0\n",
      "learning_rate 0.02,Testing Accuracy 1.0\n",
      "learning_rate 0.05,Testing Accuracy 1.0\n",
      "learning_rate 0.08,Testing Accuracy 1.0\n",
      "learning_rate 0.1,Testing Accuracy 1.0\n",
      "learning_rate 0.2,Testing Accuracy 1.0\n",
      "learning_rate 0.5,Testing Accuracy 1.0\n"
     ]
    }
   ],
   "source": [
    "# 准备好placeholder\n",
    "x = tf.placeholder(tf.float32,[None,n_features],name=\"X\")\n",
    "y = tf.placeholder(tf.float32,[None, 1],name=\"Y\")\n",
    "\n",
    "# 初始化参数/权重\n",
    "W = tf.Variable(tf.random_normal([n_features,1],stddev=0.01), name='weight')\n",
    "b = tf.Variable(1.0, name='bias')# 初始化参数/权重\n",
    "\n",
    "\n",
    "#创建一个简单的神经网络\n",
    "prediction = tf.nn.softmax(tf.matmul(x,W)+b)\n",
    "\n",
    "#二次代价函数 :MSE\n",
    "loss = tf.reduce_mean(tf.square(y-prediction))\n",
    "#使用梯度下降法\n",
    "# train_step = tf.train.GradientDescentOptimizer(learning_rate).minimize(loss)\n",
    "\n",
    "#初始化变量\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "#结果存放在一个布尔型列表中\n",
    "correct_prediction = tf.equal(tf.argmax(y,1),tf.argmax(prediction,1))\n",
    "#求准确率\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction,tf.float32))\n",
    "\n",
    "losses_tf = []\n",
    "accuracy_tf = []\n",
    "#train\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    for learning_rate_i in learning_rate_list:\n",
    "        \n",
    "        #使用梯度下降法\n",
    "        train_step = tf.train.GradientDescentOptimizer(learning_rate_i).minimize(loss)\n",
    "        loss_temp = []\n",
    "        acc_temp = []\n",
    "        for epoch in range(train_epochs):\n",
    "\n",
    "            loss_sum = 0.0\n",
    "            acc_sum = 0.0\n",
    "\n",
    "            for xs, ys in zip(X_, y_):\n",
    "                xs = xs.reshape(1,13)\n",
    "                ys = ys.reshape(1,1)\n",
    "                _, loss_epocch,acc_epocch = sess.run([train_step, loss,accuracy],feed_dict={x:X_train,y:y_train.reshape(-1,1)})\n",
    "                loss_sum += loss_epocch\n",
    "                acc_sum += acc_epocch\n",
    "\n",
    "            # 完成一次更新就 打乱数据顺序\n",
    "            X_, y_ = shuffle(X_, y_)\n",
    "            b_temp = b.eval(session = sess)\n",
    "            W_temp = W.eval(session=sess)\n",
    "\n",
    "            loss_average = loss_sum / X_.shape[0]\n",
    "            acc_average = acc_sum / X_.shape[0]\n",
    "\n",
    "            loss_temp.append(loss_average)\n",
    "            acc_temp.append(acc_average)\n",
    "            \n",
    "        losses_tf.append(loss_temp)\n",
    "        accuracy_tf.append(acc_temp)\n",
    "        \n",
    "        acc = sess.run(accuracy,feed_dict={x:X_test,y:y_test.reshape(-1,1)})\n",
    "        print(\"learning_rate \" + str(learning_rate_i) + \",Testing Accuracy \" + str(acc))\n",
    "    \n",
    "        \n",
    "#         if epoch % print_grap == 0:\n",
    "#             print(\"epoch=\",epoch+1,\"loss(MSE)=\",loss_average,\"b=\",b_temp,\"w=\",W_temp)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-10T08:28:16.413612Z",
     "start_time": "2019-11-10T08:28:15.055262Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 8 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Vilizating the data\n",
    "for i in range(1,len(losses_tf)+1):\n",
    "    plt.subplot(2,4,i)\n",
    "    plt.plot(range(len(losses_tf[i-1])), losses_tf[i-1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Observe the effect of iteration_num on the test accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
